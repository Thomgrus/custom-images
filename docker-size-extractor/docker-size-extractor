#!/usr/bin/env python3

URL_IMAGES = 'https://{repository}/v2/_catalog'
URL_TAGS = 'https://{repository}/v2/{image}/tags/list'
URL_TAG_INFO = 'https://{repository}/v2/{image}/manifests/{tag}'

IMAGE_TO_LAYERS = {}

from datetime import date
from typing import OrderedDict
import requests
from requests.models import Response

def getAllImages(repository):
    return requests.get(URL_IMAGES.format(repository = repository)).json()['repositories']

def getTagsByImage(repository, image):
    return requests.get(URL_TAGS.format(repository= repository, image=image)).json()['tags'];

def getTagLayers(repository, image, tag):
    return requests.get(URL_TAG_INFO.format(repository= repository, image=image, tag=tag)).json()['layers'];

def addLayersToStructure(image, layers):
    for layer in layers:
        IMAGE_TO_LAYERS.setdefault(image, {}).setdefault('digests', {})[layer['digest']]=layer['size']

def addNumTagsToStructure(image, number_of_tags):
    IMAGE_TO_LAYERS.setdefault(image, {})['#']=number_of_tags

def processStructure(image):
    size_in_byte = sum(IMAGE_TO_LAYERS[image]['digests'].values())
    size_in_mega_byte = round(size_in_byte / 1024 / 1024, 2)
    IMAGE_TO_LAYERS[image]['size'] = size_in_mega_byte
    return size_in_mega_byte

import json

def saveStructure(repository, date):
    with open(f'{repository}-{date}.json', 'w') as outfile:
        json.dump(IMAGE_TO_LAYERS, outfile)

def getStructureFromCache(repository, date):
    global IMAGE_TO_LAYERS
    with open(f'{repository}-{date}.json', 'r') as json_file:
        IMAGE_TO_LAYERS = json.load(json_file)

def saveResult(sorted_dict, repository, date):
    with open(f'extracts-{repository}-{date}.json', 'w') as outfile:
        json.dump(sorted_dict, outfile)

# ENTRY

def fetchStructureFromAPI(repository, date):
    all_images = getAllImages(repository)
    images_len = len(all_images)
    print(f'There is {images_len} to process')
    for index, image in enumerate(all_images):
        print(f'Process {index+1}/{images_len}:')
        tags = getTagsByImage(repository, image)
        number_of_tags = len(tags)
        addNumTagsToStructure(image, number_of_tags)
        for tag in tags:
            layers = getTagLayers(repository, image, tag)
            addLayersToStructure(image, layers)
        size = processStructure(image)
        print(f'The image {image} cost {size}mb with {number_of_tags} tags')
    saveStructure(repository, date)

def fetchStructureFromCache(repository, date):
    getStructureFromCache(repository, date)
    for image, value in IMAGE_TO_LAYERS.items():
        size = value['size']
        number_of_tags = value['#']
        print(f'The image {image} cost {size}mb with {number_of_tags} tags')

def getResults(repository, date):
    sorted_structure = sorted(IMAGE_TO_LAYERS.items(), key= lambda kv:(kv[1]['size'], kv[1]['#'], kv[0]), reverse=True)
    sorted_dict = dict(OrderedDict(sorted_structure))
    for _, value in sorted_dict.items():
        del value['digests']
    saveResult(sorted_dict, repository, date)
    print()
    print('The TOP 10:')
    for image_info in sorted_structure[:10]:
        size = image_info[1]['size']
        number_of_tags = image_info[1]['#']
        print(f'Image {image_info[0]} with {size}mb for {number_of_tags} tags')


# CSV part

import pandas as pd
import os.path
def addToCSV(repository, date):
    follow_up = {}
    if (os.path.exists(r'follow_up.json')):
        with open(r'follow_up.json', 'r') as json_file:
            follow_up = json.load(json_file)
        
    with open(f'extracts-{repository}-{date}.json', 'r') as json_file:
        extracts = json.load(json_file)
        for key, value in extracts.items():
            follow_up.setdefault(key, {})[date] = value

    with open(r'follow_up.json', 'w') as outfile:
        json.dump(follow_up, outfile)


    follow_tag = {}
    follow_size = {}
    for image, value in follow_up.items():
        for date_follow, value_follow in value.items():
            follow_tag.setdefault(image, {})[date_follow] = value_follow['#']
            follow_size.setdefault(image, {})[date_follow] = value_follow['size']

    df_tag = pd.DataFrame(follow_tag)
    df_size = pd.DataFrame(follow_size)
    df_tag.to_csv (r'follow_tag.csv')
    df_size.to_csv (r'follow_size.csv')
    

import argparse
parser = argparse.ArgumentParser()
parser.add_argument("repository", help="repository to scan")
parser.add_argument("-c", "--cache", help="use info from cache", action="store_true")
parser.add_argument("-d", "--date", help="date in format YYYYMMDD", default=date.today().strftime('%Y%m%d'))
parser.add_argument("-e", "--export", help="export data in csv", action="store_true")

args = parser.parse_args()

if (args.cache):
    fetchStructureFromCache(args.repository, args.date)
    if (not args.export):
        getResults(args.repository, args.date)
else:
    fetchStructureFromAPI(args.repository, args.date)
    getResults(args.repository, args.date)

if (args.export):
    addToCSV(args.repository, args.date)
